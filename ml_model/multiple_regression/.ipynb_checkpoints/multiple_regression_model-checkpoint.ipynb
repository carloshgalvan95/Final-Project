{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e765083",
   "metadata": {},
   "source": [
    "# import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c09811ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T04:02:20.482497Z",
     "start_time": "2022-12-02T04:02:16.911517Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import dependencies for multiple regression\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import re\n",
    "\n",
    "\n",
    "# Import dependencies for google maps API\n",
    "#from config import g_key\n",
    "import gmaps\n",
    "import requests\n",
    "import geopy.distance\n",
    "\n",
    "# Import dependencies for classifier models\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62046c59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T04:02:20.515908Z",
     "start_time": "2022-12-02T04:02:20.485492Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../db_catastro.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wp/hmx5j_bs1mjg942ctng6p4g80000gn/T/ipykernel_30805/2799299343.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import csv files to DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcatastro_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../db_catastro.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstarbucks_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../MexicoCityStarbucks.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mairbnb_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../Airbnb.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../db_catastro.csv'"
     ]
    }
   ],
   "source": [
    "# Import csv files to DataFrames\n",
    "catastro_df = pd.read_csv('../../db_catastro.csv')\n",
    "starbucks_df = pd.read_csv('../../MexicoCityStarbucks.csv')\n",
    "airbnb_df = pd.read_csv('../../Airbnb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "832cc744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T22:20:15.584401Z",
     "start_time": "2022-11-30T22:20:15.549715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nombre_col</th>\n",
       "      <th>codigo_postal</th>\n",
       "      <th>prom_valor_unitario_suelo</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>alcaldia</th>\n",
       "      <th>estado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19 DE MAYO</td>\n",
       "      <td>1210</td>\n",
       "      <td>1404.400000</td>\n",
       "      <td>19.361649</td>\n",
       "      <td>-99.253530</td>\n",
       "      <td>Álvaro Obregón</td>\n",
       "      <td>CDMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1RA VICTORIA</td>\n",
       "      <td>1150</td>\n",
       "      <td>2061.619503</td>\n",
       "      <td>19.386686</td>\n",
       "      <td>-99.201985</td>\n",
       "      <td>Álvaro Obregón</td>\n",
       "      <td>CDMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1RA VICTORIA SECCION BOSQUES</td>\n",
       "      <td>1150</td>\n",
       "      <td>1788.360000</td>\n",
       "      <td>19.387826</td>\n",
       "      <td>-99.197446</td>\n",
       "      <td>Álvaro Obregón</td>\n",
       "      <td>CDMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2DA  JALALPA TEPITO (AMPL)</td>\n",
       "      <td>1260</td>\n",
       "      <td>1063.626266</td>\n",
       "      <td>19.375080</td>\n",
       "      <td>-99.233736</td>\n",
       "      <td>Álvaro Obregón</td>\n",
       "      <td>CDMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2DA EL PIRUL (AMPL)</td>\n",
       "      <td>1210</td>\n",
       "      <td>1320.710000</td>\n",
       "      <td>19.379745</td>\n",
       "      <td>-99.242231</td>\n",
       "      <td>Álvaro Obregón</td>\n",
       "      <td>CDMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>73</td>\n",
       "      <td>GUADALUPE</td>\n",
       "      <td>16900</td>\n",
       "      <td>420.703636</td>\n",
       "      <td>19.218264</td>\n",
       "      <td>-99.120799</td>\n",
       "      <td>Xochimilco</td>\n",
       "      <td>CDMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>74</td>\n",
       "      <td>NATIVITAS LA JOYA (AMPL)</td>\n",
       "      <td>16900</td>\n",
       "      <td>711.580672</td>\n",
       "      <td>19.237250</td>\n",
       "      <td>-99.093782</td>\n",
       "      <td>Xochimilco</td>\n",
       "      <td>CDMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>75</td>\n",
       "      <td>SAN FRANCISCO TLALNEPANTLA (PBLO)</td>\n",
       "      <td>16910</td>\n",
       "      <td>338.647387</td>\n",
       "      <td>19.197937</td>\n",
       "      <td>-99.122385</td>\n",
       "      <td>Xochimilco</td>\n",
       "      <td>CDMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>76</td>\n",
       "      <td>SANTA CECILIA TEPETLAPA (PBLO)</td>\n",
       "      <td>16880</td>\n",
       "      <td>534.238763</td>\n",
       "      <td>19.217187</td>\n",
       "      <td>-99.099325</td>\n",
       "      <td>Xochimilco</td>\n",
       "      <td>CDMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>77</td>\n",
       "      <td>SAN LUIS TLAXIALTEMALCO (PBLO)</td>\n",
       "      <td>16610</td>\n",
       "      <td>667.526340</td>\n",
       "      <td>19.256973</td>\n",
       "      <td>-99.035680</td>\n",
       "      <td>Xochimilco</td>\n",
       "      <td>CDMX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1789 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                         nombre_col  codigo_postal  \\\n",
       "0              0                         19 DE MAYO           1210   \n",
       "1              1                       1RA VICTORIA           1150   \n",
       "2              2       1RA VICTORIA SECCION BOSQUES           1150   \n",
       "3              3         2DA  JALALPA TEPITO (AMPL)           1260   \n",
       "4              4                2DA EL PIRUL (AMPL)           1210   \n",
       "...          ...                                ...            ...   \n",
       "1784          73                          GUADALUPE          16900   \n",
       "1785          74           NATIVITAS LA JOYA (AMPL)          16900   \n",
       "1786          75  SAN FRANCISCO TLALNEPANTLA (PBLO)          16910   \n",
       "1787          76     SANTA CECILIA TEPETLAPA (PBLO)          16880   \n",
       "1788          77     SAN LUIS TLAXIALTEMALCO (PBLO)          16610   \n",
       "\n",
       "      prom_valor_unitario_suelo    latitud   longitud        alcaldia estado  \n",
       "0                   1404.400000  19.361649 -99.253530  Álvaro Obregón   CDMX  \n",
       "1                   2061.619503  19.386686 -99.201985  Álvaro Obregón   CDMX  \n",
       "2                   1788.360000  19.387826 -99.197446  Álvaro Obregón   CDMX  \n",
       "3                   1063.626266  19.375080 -99.233736  Álvaro Obregón   CDMX  \n",
       "4                   1320.710000  19.379745 -99.242231  Álvaro Obregón   CDMX  \n",
       "...                         ...        ...        ...             ...    ...  \n",
       "1784                 420.703636  19.218264 -99.120799      Xochimilco   CDMX  \n",
       "1785                 711.580672  19.237250 -99.093782      Xochimilco   CDMX  \n",
       "1786                 338.647387  19.197937 -99.122385      Xochimilco   CDMX  \n",
       "1787                 534.238763  19.217187 -99.099325      Xochimilco   CDMX  \n",
       "1788                 667.526340  19.256973 -99.035680      Xochimilco   CDMX  \n",
       "\n",
       "[1789 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catastro_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b85673",
   "metadata": {},
   "source": [
    "# Parse data to locate nearby Airbnbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29d3ebc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T00:20:48.659978Z",
     "start_time": "2022-11-30T22:39:19.641691Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "catastro_df['no_airbnb'] = ''\n",
    "catastro_df = catastro_df.reset_index()\n",
    "# Hacer for loop para buscar en cada una de las filas de catastro lat y lng\n",
    "for df_index, row in catastro_df.iterrows():\n",
    "    no_airbnb = 0\n",
    "    lat_cat = row['latitud']\n",
    "    lng_cat = row['longitud']\n",
    "    catastro_loc = (lat_cat,lng_cat)\n",
    "# con cada fila, hacer nested for loop para buscar en el csv de airbnb cada fila\n",
    "    for bnb_index, row in airbnb_df.iterrows():\n",
    "        lat_bnb = row['latitude']\n",
    "        lng_bnb = row['longitude']\n",
    "        airbnb_loc = (lat_bnb,lng_bnb)\n",
    "# Compara if de lat,lng de catastro if catastro_df[0] > 500m de distancia de airbnb_df[0]\n",
    "        distancia = geopy.distance.geodesic(catastro_loc, airbnb_loc).m\n",
    "        if distancia < 500:\n",
    "            no_airbnb = no_airbnb + 1\n",
    "\n",
    "    catastro_df.loc[df_index, 'no_airbnb'] = no_airbnb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f17132da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T04:02:04.999497Z",
     "start_time": "2022-12-02T04:02:01.453186Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carloshgalvan/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/geopy/point.py:472: UserWarning: Latitude normalization has been prohibited in the newer versions of geopy, because the normalized value happened to be on a different pole, which is probably not what was meant. If you pass coordinates as positional args, please make sure that the order is (latitude, longitude) or (y, x) in Cartesian terms.\n",
      "  return cls(*args)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Latitude must be in the [-90; 90] range.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wp/hmx5j_bs1mjg942ctng6p4g80000gn/T/ipykernel_30805/1834066760.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Using geopy.distance module, compare both coordinate to determine distance between them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mdistancia_starbucks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeodesic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatastro_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarbucks_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Create conditional to add 1 to the counter if Starbucks is within 500m of Catastro_df row location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/geopy/distance.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ellipsoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ellipsoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'WGS-84'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mELLIPSOID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_ellipsoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/geopy/distance.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mkilometers\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mkilometers\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkilometers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/geopy/distance.py\u001b[0m in \u001b[0;36mmeasure\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0m_ensure_same_altitude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mlat1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/geopy/point.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, latitude, longitude, altitude)\u001b[0m\n\u001b[1;32m    173\u001b[0m                     )\n\u001b[1;32m    174\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msingle_arg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/geopy/point.py\u001b[0m in \u001b[0;36mfrom_sequence\u001b[0;34m(cls, seq)\u001b[0m\n\u001b[1;32m    470\u001b[0m             raise ValueError('When creating a Point from sequence, it '\n\u001b[1;32m    471\u001b[0m                              'must not have more than 3 items.')\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/geopy/point.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, latitude, longitude, altitude)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mlatitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltitude\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0m_normalize_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/geopy/point.py\u001b[0m in \u001b[0;36m_normalize_coordinates\u001b[0;34m(latitude, longitude, altitude)\u001b[0m\n\u001b[1;32m     72\u001b[0m                       \u001b[0;34m'(latitude, longitude) or (y, x) in Cartesian terms.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                       UserWarning, stacklevel=3)\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Latitude must be in the [-90; 90] range.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Latitude must be in the [-90; 90] range."
     ]
    }
   ],
   "source": [
    "# Create columns to store number of Airbnb and Starbucks nearby\n",
    "catastro_df['no_airbnb'] = ''\n",
    "catastro_df['no_starbucks'] = ''\n",
    "catastro_df = catastro_df.reset_index()\n",
    "\n",
    "# Declare for loop to iterate over every row of catastro_df to compare distance radius\n",
    "for df_index, row in catastro_df.iterrows():\n",
    "    \n",
    "    # Declare counter variable to hold number of Airbnbs and Starbucks nearby\n",
    "    no_airbnb = 0\n",
    "    no_starbucks = 0\n",
    "    \n",
    "    # Get Latitude and Longitude of the row\n",
    "    lat_cat = row['latitud']\n",
    "    lng_cat = row['longitud']\n",
    "    \n",
    "    # Pair coordinates\n",
    "    catastro_loc = (lat_cat,lng_cat)\n",
    "\n",
    "    # With every catastro_df row, iterate and compare distances between each row of Airbnbs\n",
    "    for bnb_index, row in airbnb_df.iterrows():\n",
    "        \n",
    "        # Get Latitude and Longitude of the row\n",
    "        lat_bnb = row['latitude']\n",
    "        lng_bnb = row['longitude']\n",
    "        \n",
    "        # Pair coordinates\n",
    "        airbnb_loc = (lat_bnb,lng_bnb)\n",
    "        \n",
    "        # Using geopy.distance module, compare both coordinate to determine distance between them\n",
    "        distancia = geopy.distance.geodesic(catastro_loc, airbnb_loc).m\n",
    "        \n",
    "        # Create conditional to add 1 to the counter if Airbnb is within 500m of Catastro_df row location\n",
    "        if distancia < 500:\n",
    "            no_airbnb = no_airbnb + 1\n",
    "    \n",
    "    # After parsing on every row, append number of airbnbs nearby\n",
    "    catastro_df.loc[df_index, 'no_airbnb'] = no_airbnb\n",
    "    \n",
    "    # With every catastro_df row, iterate and compare distances between each row of Starbucks\n",
    "    for starbucks_index, row in starbucks_df.iterrows():\n",
    "        \n",
    "        # Get Latitude and Longitude of the row\n",
    "        lat_starbucks = row['Latitude']\n",
    "        lng_starbucks = row['Longitude']\n",
    "        \n",
    "        # Pair Coordinates\n",
    "        starbucks_loc = (lat_starbucks,lng_starbucks)\n",
    "        \n",
    "        # Using geopy.distance module, compare both coordinate to determine distance between them\n",
    "        distancia_starbucks = geopy.distance.geodesic(catastro_loc, starbucks_loc).m\n",
    "        \n",
    "        # Create conditional to add 1 to the counter if Starbucks is within 500m of Catastro_df row location\n",
    "        if distancia_starbucks < 500:\n",
    "            no_starbucks = no_starbucks + 1\n",
    "    \n",
    "    # After parsing on every row, append number of Starbucks nearby\n",
    "    catastro_df.loc[df_index, 'no_starbucks'] = no_starbucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c749610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7d45aef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T03:59:01.520636Z",
     "start_time": "2022-12-02T03:59:01.491947Z"
    }
   },
   "outputs": [],
   "source": [
    "catastro_df.to_csv('catastro_ml_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e49e1",
   "metadata": {},
   "source": [
    "# Parse data to locate nearby Airbnbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04df95f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Generate Multiple Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed402140",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Declare independent variables\n",
    "X = castastro_df['no_starbucks','no_airbnb']\n",
    "\n",
    "# Declare depedant variable to predict\n",
    "y = catrastro_df['prom_valor_unitario_suelo\t']\n",
    "\n",
    "# Split dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y)\n",
    "\n",
    "# Create model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Asses accuracy of the model\n",
    "print('Mean Square Error: ', mean_squared_error(y_test,y_pred))\n",
    "print('Mean Absolute Error: 'mean_absolute_error(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e8392b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Classification model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd2333",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Decision Tree Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e07c1c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Decision Tree Classifier for Airbnbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7f574",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Encode categorical columns\n",
    "le = LabelEncoder()\n",
    "catastro_encode = catastro_df.copy()\n",
    "catastro_encode['alcaldia'] = le.fit_transform(catastro_encode['alcaldia'])\n",
    "catastro_encode = catastro_encode.drop(columns = ['nombre_col','Unnamed: 0','estado'])\n",
    "\n",
    "# Define feature set and target set\n",
    "X = catastro_encode.copy()\n",
    "X = X.drop('flag_airbnb', axis = 1)\n",
    "y = catastro_encode['flag_airbnb'].values\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n",
    "\n",
    "# Scale the training and testing data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Fit the decision tree model\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model = model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate Predictions\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "cm = confusion.matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(cm, index = ['Actual 0', 'Actual 1'], columns =['Predicted 0','Predicted 1'])\n",
    "\n",
    "# Calculate accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Display Results\n",
    "print('Decision Tree Results')\n",
    "print('Confusion Matrix')\n",
    "display(cm_df)\n",
    "print(f'Accuracy Score:{acc_score}')\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda33ae",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Decision Tree Classifier for Starbucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f6d71",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define feature set and target set\n",
    "X = catastro_encode.copy()\n",
    "X = X.drop('flag_starbucks', axis = 1)\n",
    "y = catastro_encode['flag_starbucks'].values\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n",
    "\n",
    "# Scale the training and testing data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Fit the decision tree model\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model = model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate Predictions\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "cm = confusion.matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(cm, index = ['Actual 0', 'Actual 1'], columns =['Predicted 0','Predicted 1'])\n",
    "\n",
    "# Calculate accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Display Results\n",
    "print('Confusion Matrix')\n",
    "display(cm_df)\n",
    "print(f'Accuracy Score:{acc_score}')\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ff8065",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Random Forest Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ba4dc7",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Random Forest Classifier for Airbnbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c33f388",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Encode categorical columns\n",
    "le = LabelEncoder()\n",
    "catastro_encode = catastro_df.copy()\n",
    "catastro_encode['alcaldia'] = le.fit_transform(catastro_encode['alcaldia'])\n",
    "catastro_encode = catastro_encode.drop(columns = ['nombre_col','Unnamed: 0','estado'])\n",
    "\n",
    "# Define feature set and target set\n",
    "X = catastro_encode.copy()\n",
    "X = X.drop('flag_airbnb', axis = 1)\n",
    "y = catastro_encode['flag_airbnb'].values\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n",
    "\n",
    "# Scale the training and testing data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Create a Random Forest Classifier Instance\n",
    "rf_model_bnb = RandomForestClassifier(n_estimators = 128, random_state = 72)\n",
    "\n",
    "# Fit the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions using the testing data\n",
    "predictions = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "cm = confusion.matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(cm, index = ['Actual 0', 'Actual 1'], columns =['Predicted 0','Predicted 1'])\n",
    "\n",
    "# Display Results\n",
    "print('Random Forest Classifier Results')\n",
    "print('Confusion Matrix')\n",
    "display(cm_df)\n",
    "print(f'Accuracy Score:{acc_score}')\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aefb26a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Random Forest Classifier for Starbucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb6c707",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define feature set and target set\n",
    "X = catastro_encode.copy()\n",
    "X = X.drop('flag_starbucks', axis = 1)\n",
    "y = catastro_encode['flag_starbucks'].values\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n",
    "\n",
    "# Scale the training and testing data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Create a Random Forest Classifier Instance\n",
    "rf_model_bnb = RandomForestClassifier(n_estimators = 128, random_state = 72)\n",
    "\n",
    "# Fit the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions using the testing data\n",
    "predictions = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "cm = confusion.matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(cm, index = ['Actual 0', 'Actual 1'], columns =['Predicted 0','Predicted 1'])\n",
    "\n",
    "# Display Results\n",
    "print('Random Forest Classifier Results')\n",
    "print('Confusion Matrix')\n",
    "display(cm_df)\n",
    "print(f'Accuracy Score:{acc_score}')\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f9c60c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8afeea",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Gradient Boosting Classifier for Airbnbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f093b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Encode categorical columns\n",
    "le = LabelEncoder()\n",
    "catastro_encode = catastro_df.copy()\n",
    "catastro_encode['alcaldia'] = le.fit_transform(catastro_encode['alcaldia'])\n",
    "catastro_encode = catastro_encode.drop(columns = ['nombre_col','Unnamed: 0','estado'])\n",
    "\n",
    "# Define feature set and target set\n",
    "X = catastro_encode.copy()\n",
    "X = X.drop('flag_airbnb', axis = 1)\n",
    "y = catastro_encode['flag_airbnb'].values\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n",
    "\n",
    "# Scale the training and testing data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Try Different Learning Rates\n",
    "learning_rates = [0.05,0.07,0.1,0.15,0.20,0.25,0.30,0.35,0.40,\n",
    "                  0.45,0.5,0.55,0.60,0.65,0.70,0.75,0.80,0.85,0.90,0.95,1]\n",
    "\n",
    "for learning_rates in learning_rates:\n",
    "    \n",
    "    # Iterate Gradient Booster Model\n",
    "    classifier = GradientBoostingClassifier(n_estimators = 20, learning_rate = learning_rates,\n",
    "                                            max_features = 9, max_depth = 3, random_state = 0)\n",
    "    \n",
    "    # Fit the Model\n",
    "    classifier.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Print Report\n",
    "    print('Learning Rate: ', learning_rate)\n",
    "    print('Accuracy Score (training): {0:.3f}'.format(classifier.score(X_train_scaled, y_train)))\n",
    "    print('Accuracy Score (Validation): {0:.3f}'.format(classifier.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603b691",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Select the Learning Rate with better results\n",
    "classifier = GradientBoostingClassifier(n_estimators = 20, learning_rate = #TBD,\n",
    "                                        ,max_features = 9, max_depth = 3, random_state = 0)\n",
    "\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "predictions = classifier.predict(X_test_scaled)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy Score: {acc_score}')\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix\n",
    "cm_df = pd.DataFrame(cm, index = ['Actual 0', 'Actual 1'], columns =['Predicted 0','Predicted 1'])\n",
    "\n",
    "# Display Results\n",
    "print('Gradient Boosting Classifier Results')\n",
    "print('Confusion Matrix')\n",
    "display(cm_df)\n",
    "print(f'Accuracy Score:{acc_score}')\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e0e8e7",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Gradient Boosting Classifier for Starbucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9588976c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Encode categorical columns\n",
    "le = LabelEncoder()\n",
    "catastro_encode = catastro_df.copy()\n",
    "catastro_encode['alcaldia'] = le.fit_transform(catastro_encode['alcaldia'])\n",
    "catastro_encode = catastro_encode.drop(columns = ['nombre_col','Unnamed: 0','estado'])\n",
    "\n",
    "# Define feature set and target set\n",
    "X = catastro_encode.copy()\n",
    "X = X.drop('flag_starbucks', axis = 1)\n",
    "y = catastro_encode['flag_starbucks'].values\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n",
    "\n",
    "# Scale the training and testing data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Try Different Learning Rates\n",
    "learning_rates = [0.05,0.07,0.1,0.15,0.20,0.25,0.30,0.35,0.40,\n",
    "                  0.45,0.5,0.55,0.60,0.65,0.70,0.75,0.80,0.85,0.90,0.95,1]\n",
    "\n",
    "for learning_rates in learning_rates:\n",
    "    \n",
    "    # Iterate Gradient Booster Model\n",
    "    classifier = GradientBoostingClassifier(n_estimators = 20, learning_rate = learning_rates,\n",
    "                                            max_features = 9, max_depth = 3, random_state = 0)\n",
    "    \n",
    "    # Fit the Model\n",
    "    classifier.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Print Report\n",
    "    print('Learning Rate: ', learning_rate)\n",
    "    print('Accuracy Score (training): {0:.3f}'.format(classifier.score(X_train_scaled, y_train)))\n",
    "    print('Accuracy Score (Validation): {0:.3f}'.format(classifier.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b4767",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Select the Learning Rate with better results\n",
    "classifier = GradientBoostingClassifier(n_estimators = 20, learning_rate = #TBD,\n",
    "                                        ,max_features = 9, max_depth = 3, random_state = 0)\n",
    "\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "predictions = classifier.predict(X_test_scaled)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy Score: {acc_score}')\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix\n",
    "cm_df = pd.DataFrame(cm, index = ['Actual 0', 'Actual 1'], columns =['Predicted 0','Predicted 1'])\n",
    "\n",
    "# Display Results\n",
    "print('Gradient Boosting Classifier Results')\n",
    "print('Confusion Matrix')\n",
    "display(cm_df)\n",
    "print(f'Accuracy Score:{acc_score}')\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
